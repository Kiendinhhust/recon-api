# ğŸ“– HÆ¯á»šNG DáºªN CHI TIáº¾T

## Má»¤C Lá»¤C
1. [CÃ¡ch cháº¡y Selective Scanning API](#1-cÃ¡ch-cháº¡y-selective-scanning-api)
2. [CÃ¡ch Full Pipeline cháº¡y SourceLeakHacker](#2-cÃ¡ch-full-pipeline-cháº¡y-sourceleakhacker)

---

# 1. CÃCH CHáº Y SELECTIVE SCANNING API

## ğŸ¯ Má»¥c Ä‘Ã­ch
Scan **má»™t vÃ i URLs cá»¥ thá»ƒ** Ä‘á»ƒ tÃ¬m source code leaks, thay vÃ¬ scan toÃ n bá»™ domain.

## ğŸ“‹ YÃªu cáº§u
- ÄÃ£ cÃ³ má»™t scan job **hoÃ n thÃ nh** (status = "completed")
- Biáº¿t Job ID cá»§a scan Ä‘Ã³
- URLs muá»‘n scan pháº£i náº±m trong danh sÃ¡ch live hosts cá»§a job

---

## ğŸš€ CÃCH 1: DÃ¹ng Demo Script (Dá»… nháº¥t)

### BÆ°á»›c 1: Chá»‰nh sá»­a file `demo_selective_scan.py`

Má»Ÿ file vÃ  thay Ä‘á»•i 3 thÃ´ng tin:

```python
# 1. Job ID (láº¥y tá»« scan Ä‘Ã£ hoÃ n thÃ nh)
JOB_ID = "503505fb-8b9f-4255-891d-341959d5a2dd"

# 2. Danh sÃ¡ch URLs muá»‘n scan
selected_urls = [
    "https://exam.hustack.soict.ai",  # URL báº¡n Ä‘ang xem
    "https://taskforce.soict.ai",
    "https://coopy.soict.ai"
]

# 3. Scan mode
scan_mode = "tiny"  # hoáº·c "full"
```

### BÆ°á»›c 2: Cháº¡y script

```bash
python demo_selective_scan.py
```

### BÆ°á»›c 3: Xem káº¿t quáº£

Script sáº½ hiá»ƒn thá»‹:
- URLs Ä‘Æ°á»£c scan
- Sá»‘ lÆ°á»£ng leaks tÃ¬m tháº¥y
- Chi tiáº¿t tá»«ng leak (náº¿u cÃ³)

**VÃ­ dá»¥ output:**
```
ğŸ“Š BÆ¯á»šC 5: Káº¿t quáº£
--------------------------------------------------------------------------------
   HTTP Status: 200

âœ… SUCCESS!

   Job ID: 503505fb-8b9f-4255-891d-341959d5a2dd
   URLs Scanned: 3
   Leaks Found: 0
   Message: Scanned 3 URLs in 'tiny' mode, found 0 leaks

â„¹ï¸  No leaks found (domain is secure)
```

---

## ğŸ”§ CÃCH 2: DÃ¹ng cURL (Manual)

### BÆ°á»›c 1: Táº¡o file JSON vá»›i URLs

Táº¡o file `my_urls.json`:

```json
{
  "urls": [
    "https://exam.hustack.soict.ai",
    "https://taskforce.soict.ai",
    "https://coopy.soict.ai"
  ],
  "mode": "tiny"
}
```

### BÆ°á»›c 2: Gá»i API báº±ng cURL

```bash
curl -X POST http://localhost:8000/api/v1/scans/503505fb-8b9f-4255-891d-341959d5a2dd/leak-scan \
  -H "Content-Type: application/json" \
  -d @my_urls.json
```

### BÆ°á»›c 3: Xem response

```json
{
  "job_id": "503505fb-8b9f-4255-891d-341959d5a2dd",
  "urls_scanned": 3,
  "leaks_found": 0,
  "leaks": [],
  "message": "Scanned 3 URLs in 'tiny' mode, found 0 leaks"
}
```

---

## ğŸŒ CÃCH 3: DÃ¹ng Swagger UI (Giao diá»‡n web)

### BÆ°á»›c 1: Má»Ÿ Swagger UI

Truy cáº­p: http://localhost:8000/docs

### BÆ°á»›c 2: TÃ¬m endpoint

Scroll xuá»‘ng tÃ¬m endpoint:
```
POST /api/v1/scans/{job_id}/leak-scan
```

### BÆ°á»›c 3: Click "Try it out"

### BÆ°á»›c 4: Äiá»n thÃ´ng tin

- **job_id:** `503505fb-8b9f-4255-891d-341959d5a2dd`
- **Request body:**
```json
{
  "urls": [
    "https://exam.hustack.soict.ai",
    "https://taskforce.soict.ai"
  ],
  "mode": "tiny"
}
```

### BÆ°á»›c 5: Click "Execute"

### BÆ°á»›c 6: Xem response á»Ÿ pháº§n "Response body"

---

## ğŸ“ Giáº£i thÃ­ch Parameters

### `urls` (required)
- **Type:** Array of strings
- **Description:** Danh sÃ¡ch URLs muá»‘n scan
- **Example:** `["https://example.com", "https://api.example.com"]`
- **LÆ°u Ã½:** URLs pháº£i náº±m trong danh sÃ¡ch live hosts cá»§a job

### `mode` (optional, default: "tiny")
- **Type:** String
- **Values:** `"tiny"` hoáº·c `"full"`
- **Description:**
  - `tiny`: Scan nhanh vá»›i ~100 paths (1-2 phÃºt/URL)
  - `full`: Scan ká»¹ cÃ ng vá»›i ~1000 paths (10-15 phÃºt/URL)

---

## ğŸ” CÃ¡ch láº¥y danh sÃ¡ch URLs cÃ³ thá»ƒ scan

### Option 1: Tá»« file `live.txt`

```bash
# Xem file live.txt (JSON Lines format)
type jobs\503505fb-8b9f-4255-891d-341959d5a2dd\live.txt

# Extract URLs báº±ng Python
python -c "import json; [print(json.loads(line)['url']) for line in open('jobs/503505fb-8b9f-4255-891d-341959d5a2dd/live.txt')]"
```

### Option 2: Tá»« file `urls_no_waf.txt`

```bash
# Xem URLs khÃ´ng cÃ³ WAF (Ä‘Ã£ Ä‘Æ°á»£c filter sáºµn)
type jobs\503505fb-8b9f-4255-891d-341959d5a2dd\urls_no_waf.txt
```

### Option 3: Tá»« API

```bash
# Get scan results
curl http://localhost:8000/api/v1/scans/503505fb-8b9f-4255-891d-341959d5a2dd

# Filter live subdomains
curl http://localhost:8000/api/v1/scans/503505fb-8b9f-4255-891d-341959d5a2dd | python -c "import sys, json; data = json.load(sys.stdin); [print(s['subdomain']) for s in data['subdomains'] if s['is_live']]"
```

---

# 2. CÃCH FULL PIPELINE CHáº Y SOURCELEAKHACKER

## ğŸ”„ Tá»•ng quan Pipeline

Full pipeline cÃ³ **5 bÆ°á»›c chÃ­nh**:

```
1. Subdomain Discovery (subfinder, amass, assetfinder)
   â†“
2. Live Host Detection (httprobe, httpx)
   â†“
3. WAF Detection (wafw00f)
   â†“
4. Screenshot Capture (gowitness)
   â†“
5. Leak Detection (SourceLeakHacker) â† BÆ¯á»šC NÃ€Y
```

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c Job

Má»—i scan job táº¡o má»™t thÆ° má»¥c trong `jobs/`:

```
jobs/
â””â”€â”€ 503505fb-8b9f-4255-891d-341959d5a2dd/
    â”œâ”€â”€ subs.txt                 # Táº¥t cáº£ subdomains (43 domains)
    â”œâ”€â”€ httprobe.txt             # Live URLs tá»« httprobe
    â”œâ”€â”€ live.txt                 # Live URLs vá»›i metadata (JSON)
    â”œâ”€â”€ waf_results.json         # Káº¿t quáº£ WAF detection (30 URLs)
    â”œâ”€â”€ urls_no_waf.txt          # URLs khÃ´ng cÃ³ WAF (27 URLs) â† INPUT cho SourceLeakHacker
    â”œâ”€â”€ leaks_results/           # Output cá»§a SourceLeakHacker
    â”‚   â”œâ”€â”€ 200.csv              # Leaks vá»›i HTTP 200
    â”‚   â”œâ”€â”€ 403.csv              # Leaks vá»›i HTTP 403
    â”‚   â””â”€â”€ ...
    â””â”€â”€ shots/                   # Screenshots
```

---

## âš™ï¸ CÃ¡ch SourceLeakHacker Ä‘Æ°á»£c gá»i trong Pipeline

### BÆ°á»›c 1: Pipeline táº¡o file `urls_no_waf.txt`

**File:** `app/services/pipeline.py` (Lines 450-470)

```python
# Filter out WAF-protected URLs
waf_urls = {w['url'] for w in waf_detections if w['has_waf']}
non_waf_urls = [h['url'] for h in live_hosts if h['url'] not in waf_urls]

# Save to urls_no_waf.txt
self.urls_no_waf_file = self.job_dir / "urls_no_waf.txt"
with open(self.urls_no_waf_file, 'w') as f:
    for url in non_waf_urls:
        f.write(f"{url}\n")
```

**Káº¿t quáº£:** File `urls_no_waf.txt` chá»©a 27 URLs khÃ´ng cÃ³ WAF

---

### BÆ°á»›c 2: Pipeline gá»i `_run_sourceleakhacker_cli()`

**File:** `app/services/pipeline.py` (Lines 551-650)

```python
async def _run_sourceleakhacker_cli(
    self,
    live_hosts: List[Dict[str, Any]],
    waf_detections: List[Dict[str, Any]],
    mode: Optional[str] = None,
    selected_urls: Optional[List[str]] = None
) -> List[Dict[str, Any]]:
```

**Tham sá»‘:**
- `live_hosts`: Danh sÃ¡ch live hosts tá»« httpx
- `waf_detections`: Káº¿t quáº£ WAF detection
- `mode`: Scan mode ("tiny" hoáº·c "full")
- `selected_urls`: URLs cá»¥ thá»ƒ (cho selective scanning)

---

### BÆ°á»›c 3: Táº¡o file input cho SourceLeakHacker

**Code:** (Lines 560-580)

```python
if selected_urls:
    # Selective scanning: Chá»‰ scan URLs Ä‘Æ°á»£c chá»n
    urls_to_scan = selected_urls
else:
    # Full pipeline: Filter out WAF-protected URLs
    waf_urls = {w['url'] for w in waf_detections if w['has_waf']}
    urls_to_scan = [h['url'] for h in live_hosts if h['url'] not in waf_urls]

# Táº¡o file input
urls_file = self.job_dir / "urls_for_leaks.txt"
with open(urls_file, 'w') as f:
    for url in urls_to_scan:
        f.write(f"{url}\n")
```

---

### BÆ°á»›c 4: Convert paths thÃ nh absolute paths

**Code:** (Lines 596-611)

```python
# SourceLeakHacker cháº¡y tá»« directory riÃªng cá»§a nÃ³
sourceleakhacker_dir = Path(settings.sourceleakhacker_path).parent

# Convert sang absolute paths (FIX QUAN TRá»ŒNG!)
urls_file_absolute = Path(urls_file).resolve()
output_dir_absolute = Path(self.leaks_output_dir).resolve()

cmd = [
    settings.python_executable,
    str(settings.sourceleakhacker_path),
    f"--urls={str(urls_file_absolute)}",  # Absolute path
    f"--scale={scan_mode}",
    "--output", str(output_dir_absolute),  # Absolute path
    "--threads", str(getattr(settings, 'sourceleakhacker_threads', 8)),
    "--timeout", str(getattr(settings, 'sourceleakhacker_timeout', 1800))
]
```

**Táº¡i sao cáº§n absolute paths?**
- SourceLeakHacker cháº¡y tá»« `E:\SourceLeakHacker\SourceLeakHacker-master\`
- Náº¿u dÃ¹ng relative path `jobs\...\urls_no_waf.txt`, nÃ³ sáº½ tÃ¬m file trong `E:\SourceLeakHacker\...` â†’ Lá»—i!
- Absolute path: `C:\recon-api\jobs\...\urls_no_waf.txt` â†’ OK!

---

### BÆ°á»›c 5: Cháº¡y SourceLeakHacker

**Code:** (Lines 613-625)

```python
# Cháº¡y subprocess
result = subprocess.run(
    cmd,
    cwd=str(sourceleakhacker_dir),  # Working directory
    capture_output=True,
    text=True,
    timeout=timeout
)

# Log output
self.logger.info(f"SourceLeakHacker STDOUT:\n{result.stdout}")
if result.stderr:
    self.logger.warning(f"SourceLeakHacker STDERR:\n{result.stderr}")
```

**Command thá»±c táº¿:**
```bash
cd E:\SourceLeakHacker\SourceLeakHacker-master\
python SourceLeakHacker.py \
  --urls=C:\recon-api\jobs\503505fb...\urls_no_waf.txt \
  --scale=tiny \
  --output C:\recon-api\jobs\503505fb...\leaks_results \
  --threads 8 \
  --timeout 1800
```

---

### BÆ°á»›c 6: Parse káº¿t quáº£

**Code:** (Lines 627-650)

SourceLeakHacker cÃ³ 2 output formats:

#### Format 1: STDOUT
```
[200] 1234 0.5s text/html https://example.com/.git/config
[403] 567 0.3s text/plain https://example.com/.env
```

#### Format 2: CSV files
```
leaks_results/
â”œâ”€â”€ 200.csv
â”œâ”€â”€ 403.csv
â””â”€â”€ 404.csv
```

**CSV format:**
```csv
Code,Length,Time,Type,URL
200,1234,0.5s,text/html,https://example.com/.git/config
```

**Parsing code:**
```python
# Parse STDOUT
for line in result.stdout.split('\n'):
    match = re.match(r'\[(\d+)\]\s+(\d+)\s+([\d.]+)s?\s+(\S+)\s+(.+)', line)
    if match:
        leaks.append({
            'http_status': int(match.group(1)),
            'content_length': int(match.group(2)),
            'response_time': float(match.group(3)),
            'content_type': match.group(4),
            'leaked_file_url': match.group(5),
            ...
        })

# Parse CSV files
for csv_file in output_dir.glob('*.csv'):
    with open(csv_file, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            leaks.append({
                'http_status': int(row['Code']),
                'content_length': int(row['Length']),
                'leaked_file_url': row['URL'],
                ...
            })
```

---

### BÆ°á»›c 7: LÆ°u vÃ o database

**Code:** (Lines 140-160 trong `app/workers/tasks.py`)

```python
# Save leaks to database
if leaks:
    leak_repo = LeakDetectionRepository(db)
    leak_repo.bulk_create(scan_job.id, leaks)
    
    # Update scan job
    scan_repo.update_scan_status(
        job_id,
        ScanStatus.COMPLETED,
        leaks_found=len(leaks)
    )
```

---

## ğŸ” CÃ¡ch kiá»ƒm tra SourceLeakHacker Ä‘Ã£ cháº¡y

### Check 1: File `urls_no_waf.txt` tá»“n táº¡i

```bash
type jobs\503505fb-8b9f-4255-891d-341959d5a2dd\urls_no_waf.txt
```

**Ká»³ vá»ng:** 27 URLs

---

### Check 2: Directory `leaks_results/` tá»“n táº¡i

```bash
dir jobs\503505fb-8b9f-4255-891d-341959d5a2dd\leaks_results
```

**Ká»³ vá»ng:** Directory tá»“n táº¡i (cÃ³ thá»ƒ rá»—ng náº¿u khÃ´ng tÃ¬m tháº¥y leaks)

---

### Check 3: Database cÃ³ leak records

```bash
curl http://localhost:8000/api/v1/scans/503505fb-8b9f-4255-891d-341959d5a2dd
```

**Ká»³ vá»ng:** `"leak_detections": [...]`

---

### Check 4: Worker logs

Xem terminal window cá»§a Celery worker, tÃ¬m dÃ²ng:

```
[INFO] [503505fb...] SourceLeakHacker command: python E:\SourceLeakHacker\...
[INFO] [503505fb...] SourceLeakHacker completed in X seconds
[INFO] [503505fb...] Found X leaks
```

---

## ğŸ“Š Flow Chart

```mermaid
graph TD
    A[Start Full Pipeline] --> B[Subdomain Discovery]
    B --> C[Live Host Detection]
    C --> D[WAF Detection]
    D --> E{Filter WAF URLs}
    E --> F[Create urls_no_waf.txt]
    F --> G[Convert to Absolute Paths]
    G --> H[Run SourceLeakHacker]
    H --> I[Parse STDOUT]
    H --> J[Parse CSV Files]
    I --> K[Merge Results]
    J --> K
    K --> L[Save to Database]
    L --> M[Update Job Status]
    M --> N[End]
```

---

## ğŸ¯ TÃ³m táº¯t

### Full Pipeline:
1. âœ… Tá»± Ä‘á»™ng filter WAF-protected URLs
2. âœ… Táº¡o file `urls_no_waf.txt`
3. âœ… Convert sang absolute paths
4. âœ… Cháº¡y SourceLeakHacker vá»›i mode tá»« `.env`
5. âœ… Parse káº¿t quáº£ tá»« STDOUT vÃ  CSV
6. âœ… LÆ°u vÃ o database

### Selective Scanning:
1. âœ… User chá»n URLs cá»¥ thá»ƒ
2. âœ… Táº¡o file input táº¡m thá»i
3. âœ… Convert sang absolute paths
4. âœ… Cháº¡y SourceLeakHacker vá»›i mode tá»« request
5. âœ… Parse káº¿t quáº£
6. âœ… Return trá»±c tiáº¿p qua API (khÃ´ng lÆ°u database)

---

**End of Guide**

