# üöÄ H∆∞·ªõng d·∫´n Setup v√† S·ª≠ d·ª•ng Recon API

## üìã M·ª•c l·ª•c
1. [C√†i ƒë·∫∑t Tools](#1-c√†i-ƒë·∫∑t-tools)
2. [Setup Database v√† Redis](#2-setup-database-v√†-redis)
3. [C√†i ƒë·∫∑t Python Dependencies](#3-c√†i-ƒë·∫∑t-python-dependencies)
4. [Ch·∫°y h·ªá th·ªëng](#4-ch·∫°y-h·ªá-th·ªëng)
5. [S·ª≠ d·ª•ng API](#5-s·ª≠-d·ª•ng-api)
6. [Troubleshooting](#6-troubleshooting)

---

## 1. C√†i ƒë·∫∑t Tools

### C√†i ƒë·∫∑t Go (n·∫øu ch∆∞a c√≥)
```bash
# Download v√† c√†i ƒë·∫∑t Go
wget https://go.dev/dl/go1.21.0.linux-amd64.tar.gz
sudo tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz

# Th√™m v√†o ~/.bashrc ho·∫∑c ~/.zshrc
export PATH=$PATH:/usr/local/go/bin
export GOPATH=$HOME/go
export PATH=$PATH:$GOPATH/bin

# Reload shell
source ~/.bashrc
```

### C√†i ƒë·∫∑t Recon Tools
```bash
# Subfinder - Subdomain discovery
go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest

# Httpx - HTTP toolkit
go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest

# Assetfinder - Find domains and subdomains
go install -v github.com/tomnomnom/assetfinder@latest

# Httprobe - Take a list of domains and probe for working HTTP/HTTPS servers
go install -v github.com/tomnomnom/httprobe@latest

# Anew - Append lines from stdin to a file, but only if they don't already appear
go install -v github.com/tomnomnom/anew@latest

# Gowitness - Web screenshot utility
go install -v github.com/sensepost/gowitness@latest

# Amass - In-depth attack surface mapping
# Download binary
wget https://github.com/owasp-amass/amass/releases/download/v4.2.0/amass_Linux_amd64.zip
unzip amass_Linux_amd64.zip
sudo mv amass_Linux_amd64/amass /usr/local/bin/
rm -rf amass_Linux_amd64*
```

### Verify Tools Installation
```bash
# Check t·∫•t c·∫£ tools ƒë√£ c√†i ƒë·∫∑t
subfinder -version
amass -version
assetfinder -h
httprobe -h
httpx -version
anew -h
gowitness version
```

---

## 2. Setup Database v√† Redis

### C√†i ƒë·∫∑t PostgreSQL
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install postgresql postgresql-contrib

# Start PostgreSQL
sudo systemctl start postgresql
sudo systemctl enable postgresql

# T·∫°o database
sudo -u postgres psql
```

Trong PostgreSQL shell:
```sql
CREATE DATABASE recon_db;
CREATE USER recon_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE recon_db TO recon_user;
\q
```

### C√†i ƒë·∫∑t Redis
```bash
# Ubuntu/Debian
sudo apt install redis-server

# Start Redis
sudo systemctl start redis
sudo systemctl enable redis

# Test Redis
redis-cli ping
# Should return: PONG
```

---

## 3. C√†i ƒë·∫∑t Python Dependencies

```bash
# Clone repository
cd recon-api

# T·∫°o virtual environment (khuy·∫øn ngh·ªã)
python3 -m venv venv
source venv/bin/activate

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# Copy v√† c·∫•u h√¨nh .env
cp .env.example .env
```

### C·∫•u h√¨nh .env file
```bash
nano .env
```

N·ªôi dung:
```env
# Database Configuration
DATABASE_URL=postgresql://recon_user:your_password@localhost:5432/recon_db

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# API Configuration
API_TITLE=Recon API
API_VERSION=1.0.0

# CORS Configuration
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080", "http://localhost:8000"]

# File Storage
JOBS_DIRECTORY=./jobs

# Tool Paths
SUBFINDER_PATH=subfinder
AMASS_PATH=amass
ASSETFINDER_PATH=assetfinder
HTTPX_PATH=httpx
HTTPROBE_PATH=httprobe
ANEW_PATH=anew
GOWITNESS_PATH=gowitness
```

### Kh·ªüi t·∫°o Database
```bash
# T·∫°o tables
python scripts/init_db.py

# Ho·∫∑c d√πng Alembic
alembic upgrade head
```

---

## 4. Ch·∫°y h·ªá th·ªëng

### Option 1: Ch·∫°y th·ªß c√¥ng (Development)

**Terminal 1 - API Server:**
```bash
source venv/bin/activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Celery Worker:**
```bash
source venv/bin/activate
celery -A app.workers.celery_app worker --loglevel=info --concurrency=2
```

**Terminal 3 - Celery Flower (Optional - Monitoring):**
```bash
source venv/bin/activate
celery -A app.workers.celery_app flower
```

### Option 2: S·ª≠ d·ª•ng Makefile

```bash
# Terminal 1 - API
make dev

# Terminal 2 - Worker
make worker

# Ho·∫∑c ch·∫°y multiple workers
make worker-multi
```

### Option 3: Docker (Production)

```bash
# Build images
docker-compose build

# Start all services
docker-compose up -d

# Check logs
docker-compose logs -f

# Initialize database
docker-compose exec api alembic upgrade head
```

---

## 5. S·ª≠ d·ª•ng API

### Truy c·∫≠p Web Interface
M·ªü browser: `http://localhost:8000`

### Truy c·∫≠p API Documentation
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### S·ª≠ d·ª•ng API qua cURL

**1. T·∫°o Scan Job:**
```bash
curl -X POST "http://localhost:8000/api/v1/scans" \
     -H "Content-Type: application/json" \
     -d '{"domain": "fpt.ai"}'
```

Response:
```json
{
  "job_id": "abc123-def456-ghi789",
  "domain": "fpt.ai",
  "status": "pending",
  "message": "Scan job created successfully. Task ID: ..."
}
```

**2. Check Progress:**
```bash
curl "http://localhost:8000/api/v1/scans/{job_id}/progress"
```

Response:
```json
{
  "job_id": "abc123-def456-ghi789",
  "status": "running",
  "progress": {
    "current": 65,
    "total": 100,
    "status": "Running httpx for detailed analysis..."
  }
}
```

**3. Get Results:**
```bash
curl "http://localhost:8000/api/v1/scans/{job_id}"
```

Response:
```json
{
  "job_id": "abc123-def456-ghi789",
  "domain": "fpt.ai",
  "status": "completed",
  "subdomains": [
    {
      "id": 1,
      "subdomain": "bot.fpt.ai",
      "status": "live",
      "is_live": true,
      "http_status": 200
    },
    ...
  ],
  "screenshots": [
    {
      "id": 1,
      "url": "https://bot.fpt.ai",
      "filename": "bot_fpt_ai.png",
      "file_path": "jobs/abc123/shots/bot_fpt_ai.png"
    },
    ...
  ]
}
```

**4. List All Scans:**
```bash
curl "http://localhost:8000/api/v1/scans?limit=10"
```

**5. Delete Scan:**
```bash
curl -X DELETE "http://localhost:8000/api/v1/scans/{job_id}"
```

### S·ª≠ d·ª•ng Python Client

```python
import requests

# T·∫°o scan
response = requests.post(
    "http://localhost:8000/api/v1/scans",
    json={"domain": "fpt.ai"}
)
job_id = response.json()["job_id"]
print(f"Job ID: {job_id}")

# Check progress
import time
while True:
    progress = requests.get(f"http://localhost:8000/api/v1/scans/{job_id}/progress")
    data = progress.json()
    print(f"Progress: {data}")
    
    if data.get("status") in ["completed", "failed"]:
        break
    
    time.sleep(5)

# Get results
results = requests.get(f"http://localhost:8000/api/v1/scans/{job_id}")
print(results.json())
```

---

## 6. Troubleshooting

### L·ªói: Tools not found
```bash
# Ki·ªÉm tra PATH
echo $PATH | grep go

# Verify tools
which subfinder
which amass
which httpx
```

### L·ªói: Database connection
```bash
# Check PostgreSQL running
sudo systemctl status postgresql

# Test connection
psql -U recon_user -d recon_db -h localhost
```

### L·ªói: Redis connection
```bash
# Check Redis running
sudo systemctl status redis

# Test connection
redis-cli ping
```

### L·ªói: Celery worker not processing
```bash
# Check Redis connection
redis-cli ping

# Check Celery logs
celery -A app.workers.celery_app inspect active

# Restart worker
pkill -f celery
make worker
```

### View Logs
```bash
# API logs
tail -f logs/api.log

# Worker logs
tail -f logs/worker.log

# Docker logs
docker-compose logs -f api
docker-compose logs -f worker
```

---

## üìä Monitoring

### Celery Flower
Access: `http://localhost:5555`

Features:
- View active tasks
- Monitor worker status
- Task history
- Performance metrics

### Check Job Files
```bash
# List all jobs
ls -la jobs/

# View specific job
ls -la jobs/{job_id}/

# View subdomains found
cat jobs/{job_id}/subs.txt

# View live hosts
cat jobs/{job_id}/live.txt

# View screenshots
ls -la jobs/{job_id}/shots/
```

---

## üéØ Tips & Best Practices

1. **Performance**: S·ª≠ d·ª•ng `make worker-multi` ƒë·ªÉ ch·∫°y multiple workers
2. **Monitoring**: Lu√¥n ch·∫°y Flower ƒë·ªÉ monitor tasks
3. **Cleanup**: ƒê·ªãnh k·ª≥ cleanup old jobs ƒë·ªÉ ti·∫øt ki·ªám disk space
4. **Security**: Ch·ªâ scan domains b·∫°n c√≥ quy·ªÅn
5. **Rate Limiting**: C√¢n nh·∫Øc th√™m rate limiting cho production

---

## üÜò Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. Check logs
2. Verify tools installation
3. Check database/Redis connection
4. Review configuration in .env file
